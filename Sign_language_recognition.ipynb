{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing PyTorch and setting up device-agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(r\"C:\\Users\\197as\\OneDrive\\Documents\\PBL\\Indian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/197as/OneDrive/Documents/PBL/Indian/train'),\n",
       " WindowsPath('C:/Users/197as/OneDrive/Documents/PBL/Indian/test'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = dataset_path / \"train\"\n",
    "test_dir = dataset_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data with `torchvision.transforms`(with data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading image data using `ImageFolder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset ImageFolder\n",
       "     Number of datapoints: 29923\n",
       "     Root location: C:\\Users\\197as\\OneDrive\\Documents\\PBL\\Indian\\train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                TrivialAugmentWide(num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset ImageFolder\n",
       "     Number of datapoints: 12822\n",
       "     Root location: C:\\Users\\197as\\OneDrive\\Documents\\PBL\\Indian\\test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir,\n",
    "                                  transform=train_transforms)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir,\n",
    "                                 transform=test_transforms)\n",
    "\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `train_step()`, `test_step()` and `train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\197as\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch.utils.data\n",
    "\n",
    "def train_step(\n",
    "        model: torch.nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        device=device,\n",
    "        ):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch, (X,Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, Y)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "#========================================================================================\n",
    "\n",
    "def test_step(\n",
    "        model: torch.nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        device=device,\n",
    "        ):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "          \n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            loss = loss_fn(test_pred_logits, Y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    return test_loss\n",
    "\n",
    "#========================================================================================\n",
    "\n",
    "def train(\n",
    "        model: torch.nn.Module,\n",
    "        train_dataloader: torch.utils.data.DataLoader,\n",
    "        test_dataloader: torch.utils.data.DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "        epochs: int = 5\n",
    "        ):\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "    }\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_step(model=model,\n",
    "                                dataloader=train_dataloader,\n",
    "                                loss_fn=loss_fn,\n",
    "                                optimizer=optimizer,\n",
    "                                device=device)\n",
    "        \n",
    "        test_loss = test_step(model=model,\n",
    "                              dataloader=test_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              device=device)\n",
    "        \n",
    "        print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Test loss: {test_loss:.4f}\")\n",
    "        \n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*15*15,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [10:02<40:11, 602.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.7592 | Test loss: 0.0070\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model_1 = TinyVGG(\n",
    "    input_shape=3, # Number of color channels in out image data\n",
    "    hidden_units=260,\n",
    "    output_shape=len(train_data.classes),\n",
    "    ).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "model_0_results = train(model=model_1,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_curves(results: dict[str, list[float]]):\n",
    "    \"\"\"Plots training curve of a results dictionary.\"\"\"\n",
    "    # Get the loss values of the results dictionary(training and test)\n",
    "    loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "\n",
    "    # Figure out how many epochs there were\n",
    "    epochs = range(len(results[\"train_loss\"]))\n",
    "\n",
    "    # Setup a plot\n",
    "    plt.figure(figsize=(15,7))\n",
    "\n",
    "    # Plot the loss\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, loss, label=\"train_loss\")\n",
    "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_curves(model_0_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "def pred_and_plot_image(model: torch.nn.Module,\n",
    "                        image_path: str,\n",
    "                        class_names: list[str] = None,\n",
    "                        device=device):\n",
    "    \"\"\"Make a prediction on a target image and plot the image and prediction.\"\"\"\n",
    "    custom_image_uint8 = torchvision.io.read_image(image_path)\n",
    "    custom_image_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64))])\n",
    "    custom_image_transformed = custom_image_transform(custom_image_uint8)\n",
    "    custom_image = custom_image_transformed.type(torch.float32) / 255\n",
    "    custom_image = custom_image.unsqueeze(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        custom_image_pred = model(custom_image.to(device))\n",
    "    \n",
    "    custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n",
    "    custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=1)\n",
    "    return class_names[custom_image_pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_and_plot_image(\n",
    "    model=model_1,\n",
    "    image_path=Path(r\"C:\\Users\\197as\\OneDrive\\Documents\\PBL\\Indian\\70.jpeg\"),\n",
    "    class_names=test_data.classes,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\cnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True,\n",
    "                 exist_ok=True)\n",
    "\n",
    "# Create a model save\n",
    "MODEL_NAME = \"cnn_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(model_1.state_dict(),\n",
    "           MODEL_SAVE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\197as\\AppData\\Local\\Temp\\ipykernel_644\\1607096181.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'conv_block_1.0.weight': tensor([[[[ 0.1161,  0.1419, -0.0713],\n",
      "          [ 0.1581, -0.0483,  0.0297],\n",
      "          [-0.1254,  0.0945,  0.1428]],\n",
      "\n",
      "         [[-0.1562,  0.1684,  0.0264],\n",
      "          [ 0.1276,  0.0333,  0.0967],\n",
      "          [-0.0493,  0.1452,  0.0158]],\n",
      "\n",
      "         [[-0.1492,  0.0113, -0.1310],\n",
      "          [-0.0866, -0.1170,  0.0937],\n",
      "          [-0.2366, -0.1526, -0.1152]]],\n",
      "\n",
      "\n",
      "        [[[-0.1506, -0.0073, -0.2421],\n",
      "          [ 0.1550, -0.1647,  0.1125],\n",
      "          [-0.0150, -0.0858,  0.0654]],\n",
      "\n",
      "         [[ 0.0219,  0.1593,  0.0024],\n",
      "          [-0.0596,  0.0717, -0.0659],\n",
      "          [ 0.0532,  0.1664,  0.0764]],\n",
      "\n",
      "         [[-0.1619,  0.0447, -0.0452],\n",
      "          [ 0.0366, -0.1615, -0.2536],\n",
      "          [-0.1626, -0.2162,  0.0754]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0955,  0.1210,  0.0833],\n",
      "          [ 0.0387,  0.1888, -0.1196],\n",
      "          [ 0.0507, -0.0939,  0.0839]],\n",
      "\n",
      "         [[-0.0418,  0.0623, -0.0625],\n",
      "          [ 0.1907, -0.1156, -0.1477],\n",
      "          [-0.0805,  0.1811,  0.0443]],\n",
      "\n",
      "         [[ 0.1957, -0.1783, -0.2351],\n",
      "          [-0.1296, -0.1469,  0.0327],\n",
      "          [ 0.1067,  0.1621, -0.1283]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0182,  0.1759,  0.0313],\n",
      "          [-0.0391, -0.0734, -0.2005],\n",
      "          [ 0.1194, -0.2289, -0.2363]],\n",
      "\n",
      "         [[ 0.0525,  0.0239,  0.0585],\n",
      "          [ 0.0237,  0.1968, -0.2073],\n",
      "          [-0.1391, -0.0080, -0.2443]],\n",
      "\n",
      "         [[-0.1209,  0.2050,  0.1306],\n",
      "          [-0.0336,  0.0864,  0.0486],\n",
      "          [-0.0183,  0.1509, -0.0267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1173, -0.1702, -0.0989],\n",
      "          [ 0.0137,  0.0766, -0.1037],\n",
      "          [ 0.1380, -0.1660, -0.0856]],\n",
      "\n",
      "         [[ 0.1273, -0.1909, -0.2240],\n",
      "          [-0.0674, -0.1933,  0.0473],\n",
      "          [-0.0300, -0.0647,  0.1136]],\n",
      "\n",
      "         [[-0.0011, -0.1935, -0.1894],\n",
      "          [ 0.1112,  0.0689,  0.1107],\n",
      "          [-0.1522, -0.0294,  0.1827]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0990,  0.0801,  0.1337],\n",
      "          [-0.1058, -0.2018,  0.0587],\n",
      "          [ 0.0941, -0.0903, -0.0588]],\n",
      "\n",
      "         [[-0.0860, -0.2294, -0.1142],\n",
      "          [-0.1193,  0.0243, -0.0976],\n",
      "          [ 0.0647,  0.1552, -0.0600]],\n",
      "\n",
      "         [[-0.1365, -0.1878, -0.0542],\n",
      "          [-0.2374,  0.0923,  0.1396],\n",
      "          [ 0.0055,  0.1565,  0.0850]]]], device='cuda:0'), 'conv_block_1.0.bias': tensor([ 7.2953e-02,  1.0866e-01, -1.2437e-01,  2.4650e-02,  9.6326e-02,\n",
      "        -3.1307e-02, -1.0246e-01, -5.1788e-02, -8.4983e-02, -6.4567e-02,\n",
      "        -1.2851e-01, -5.5328e-02,  1.5690e-01, -7.6350e-02,  3.1153e-02,\n",
      "        -1.8396e-01, -1.4207e-01,  1.8924e-02,  9.8021e-02, -2.1433e-01,\n",
      "         4.2718e-02,  3.1653e-02, -1.2223e-01, -1.4298e-01, -1.2524e-03,\n",
      "        -1.4039e-01,  1.0346e-01, -1.6216e-01,  1.3533e-01, -5.5324e-02,\n",
      "         5.3597e-02,  3.0851e-02, -1.9083e-01, -1.3750e-01,  1.0751e-05,\n",
      "         2.2094e-02,  2.9048e-02, -7.7153e-02,  1.3280e-02, -1.4913e-01,\n",
      "        -4.3653e-02,  4.4861e-02, -5.1996e-02, -2.8442e-01,  1.9385e-02,\n",
      "        -4.1410e-02,  2.3059e-02, -7.5392e-02,  2.7849e-02,  1.2486e-03,\n",
      "        -1.2899e-01,  4.2263e-02,  4.3743e-02,  2.5826e-02,  1.4741e-01,\n",
      "        -3.8632e-03,  7.0635e-03, -2.5300e-03, -1.5346e-01,  6.7792e-02,\n",
      "         8.7189e-02,  3.1444e-02, -1.3357e-01,  9.2378e-02, -2.7127e-02,\n",
      "         1.0600e-01,  6.1802e-02,  1.4166e-02,  7.2894e-03,  4.4784e-04,\n",
      "         1.1837e-01,  1.7302e-02,  9.4231e-04, -1.6807e-01, -2.2056e-01,\n",
      "        -7.2668e-02, -1.0576e-01,  6.2213e-02, -9.9002e-02, -2.4214e-01,\n",
      "         1.0617e-01,  1.1537e-01, -2.1467e-01,  5.7889e-02,  3.9485e-02,\n",
      "         1.5678e-01,  1.0563e-02,  7.4026e-03,  1.7942e-01,  4.1668e-02,\n",
      "         2.2362e-02,  9.8524e-02, -1.2821e-01,  6.8508e-03,  5.1429e-03,\n",
      "        -1.9929e-01, -2.0542e-01, -1.5524e-01,  9.2327e-02,  1.2303e-01,\n",
      "        -5.2142e-02, -8.9703e-02,  1.1499e-03, -1.6665e-01,  5.4449e-02,\n",
      "        -1.7404e-01, -1.8334e-01, -1.6188e-01, -4.7694e-02,  8.7159e-02,\n",
      "         1.3306e-02,  3.7387e-02, -2.0225e-01, -1.9580e-01,  7.6326e-02,\n",
      "         4.0816e-02,  9.0062e-02, -2.0020e-01,  8.0417e-03, -2.4281e-01,\n",
      "        -4.5026e-02,  3.5278e-02,  7.9293e-02,  1.4674e-02, -1.8192e-01,\n",
      "        -1.8178e-01, -5.7982e-02,  1.7339e-01,  2.8758e-02,  5.2727e-02,\n",
      "        -1.4840e-01, -1.5972e-01,  1.0684e-01,  8.9576e-02, -1.3883e-01,\n",
      "         2.7533e-02,  1.3621e-01,  3.1263e-02, -1.6128e-01, -1.2805e-01,\n",
      "         5.9148e-02,  2.5961e-02, -1.0807e-03, -1.8626e-02,  1.6127e-02,\n",
      "         5.3195e-02, -1.8449e-01,  4.1781e-02, -1.7818e-01, -3.0642e-02,\n",
      "        -2.3567e-01,  8.1112e-02, -4.9453e-02,  7.9259e-03, -1.4730e-01,\n",
      "         2.2319e-02, -1.5199e-01, -1.5296e-01, -1.1168e-01,  8.9919e-02,\n",
      "        -2.5697e-02, -7.8958e-02,  9.6473e-02,  1.2781e-01, -8.8364e-02,\n",
      "        -2.3926e-02, -9.1213e-02, -1.4822e-01, -9.3891e-02,  2.1616e-02,\n",
      "        -1.7404e-01, -1.8092e-01,  8.5493e-02, -9.1293e-02, -5.9703e-02,\n",
      "         8.0764e-02, -3.6657e-02,  1.3826e-02, -8.7461e-02, -3.4942e-02,\n",
      "        -1.7503e-01, -1.3597e-02, -1.4686e-01,  4.5859e-02, -2.7535e-02,\n",
      "        -6.3759e-02, -5.8420e-02,  5.0933e-02,  6.8841e-02,  2.9076e-02,\n",
      "         2.9933e-02, -2.3710e-01, -1.1572e-01, -1.0648e-01, -1.8361e-01,\n",
      "         1.3457e-02, -7.4597e-02,  1.7364e-02, -1.2115e-01, -1.7805e-01,\n",
      "        -8.6674e-02, -2.1109e-01,  2.2775e-02, -1.7863e-01,  1.4978e-02,\n",
      "         7.2845e-03, -1.2238e-01, -8.6945e-02, -2.2743e-01,  5.9197e-02,\n",
      "        -1.1305e-01, -6.4580e-02,  1.4235e-02,  6.0918e-02, -5.4947e-02,\n",
      "         3.0249e-02,  6.3501e-02, -9.0658e-02,  1.2545e-02, -1.9814e-01,\n",
      "         3.9401e-02,  1.4059e-02,  4.5351e-02,  1.0946e-01,  3.7543e-02,\n",
      "        -1.3357e-01,  1.5033e-01,  6.5022e-02,  5.3012e-03,  1.0431e-01,\n",
      "        -3.4662e-02, -2.8494e-02, -1.7811e-01,  4.9703e-02,  7.9603e-03,\n",
      "         9.2261e-02,  8.8271e-02,  8.3887e-02,  7.2552e-03, -4.7650e-02,\n",
      "        -2.2710e-01, -5.3055e-02,  1.5949e-01,  9.6461e-02, -2.9134e-02,\n",
      "         4.3460e-03,  1.1117e-01, -9.1561e-02, -1.9360e-01, -1.2430e-01,\n",
      "         3.8650e-02,  2.3653e-02,  3.6679e-02,  1.5291e-02, -7.4590e-02,\n",
      "         8.4296e-02, -1.2789e-02, -1.2898e-01, -1.4187e-01, -2.3584e-02],\n",
      "       device='cuda:0'), 'conv_block_1.2.weight': tensor([[[[ 1.2660e-02, -2.0303e-02, -4.1359e-03],\n",
      "          [-2.6156e-02,  6.8808e-03, -4.8740e-04],\n",
      "          [-1.1852e-02,  4.3421e-03,  3.9979e-03]],\n",
      "\n",
      "         [[ 7.3491e-03, -2.5112e-03, -6.3831e-03],\n",
      "          [ 3.4018e-03,  3.8866e-04, -2.2098e-02],\n",
      "          [-1.4534e-02,  8.1985e-03, -1.5107e-02]],\n",
      "\n",
      "         [[ 7.6588e-03, -1.1230e-02,  1.8516e-02],\n",
      "          [-1.9721e-02,  1.2650e-02, -1.5214e-02],\n",
      "          [ 1.0612e-02,  4.9028e-03,  8.4325e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8623e-02, -8.2141e-03, -8.4779e-03],\n",
      "          [-9.5549e-03,  3.5638e-03, -6.8901e-03],\n",
      "          [-3.3819e-03,  3.8807e-03, -5.9317e-03]],\n",
      "\n",
      "         [[-2.6565e-02, -1.2457e-02,  8.0850e-03],\n",
      "          [ 4.4412e-03,  1.4168e-02,  1.2829e-02],\n",
      "          [-1.7033e-02,  2.0337e-04, -8.8351e-03]],\n",
      "\n",
      "         [[-1.1660e-02,  1.1248e-02, -2.7242e-02],\n",
      "          [-6.5031e-04,  1.5725e-02, -1.8068e-02],\n",
      "          [ 1.1845e-02, -2.2381e-02, -3.0772e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.6371e-02,  1.9409e-03, -7.9107e-05],\n",
      "          [-4.3480e-05, -9.2797e-03, -1.0997e-02],\n",
      "          [-2.4591e-02, -1.1557e-03,  1.5134e-02]],\n",
      "\n",
      "         [[-2.0135e-02, -1.2533e-02,  8.3935e-04],\n",
      "          [ 6.0019e-03,  2.9393e-03,  8.8164e-03],\n",
      "          [-1.9391e-03, -9.6437e-03, -2.1799e-02]],\n",
      "\n",
      "         [[-2.5727e-02, -2.0410e-02,  3.3228e-03],\n",
      "          [ 1.4903e-02,  1.5170e-02,  9.2882e-03],\n",
      "          [-3.2341e-03,  1.0991e-02,  2.9179e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0493e-02, -9.0781e-03, -1.1357e-02],\n",
      "          [ 3.9100e-03, -1.8559e-02, -1.4722e-02],\n",
      "          [-1.4622e-02, -1.3641e-03, -4.5521e-03]],\n",
      "\n",
      "         [[-4.7015e-03,  7.0380e-03, -1.4172e-02],\n",
      "          [ 1.9229e-02,  4.3503e-03,  1.0663e-02],\n",
      "          [-2.7870e-02,  1.0034e-02,  3.4903e-03]],\n",
      "\n",
      "         [[ 8.6720e-03,  6.3426e-03, -1.4283e-02],\n",
      "          [-9.6676e-03, -4.0014e-03,  4.0787e-04],\n",
      "          [-2.4353e-02, -8.5952e-03, -2.4155e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.9616e-02, -3.9462e-02, -4.1030e-02],\n",
      "          [-2.7033e-02, -1.3964e-02, -3.0321e-02],\n",
      "          [-3.0721e-02, -1.1145e-02, -7.9281e-03]],\n",
      "\n",
      "         [[ 1.4067e-02, -2.6236e-03, -4.1873e-03],\n",
      "          [-2.2300e-02, -1.5974e-03, -7.3276e-04],\n",
      "          [-1.8514e-04, -5.1022e-03, -2.1845e-02]],\n",
      "\n",
      "         [[-2.0668e-02, -3.9328e-02, -4.1679e-02],\n",
      "          [-4.3768e-02, -2.5962e-02, -4.3448e-02],\n",
      "          [-1.8634e-02, -1.3185e-02,  2.3197e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7854e-03, -3.5899e-02,  1.8139e-02],\n",
      "          [-3.3306e-02, -2.6390e-02, -2.4637e-02],\n",
      "          [-3.6509e-02, -1.5754e-02,  2.7786e-02]],\n",
      "\n",
      "         [[ 1.2521e-02,  1.0161e-02, -1.1721e-02],\n",
      "          [-6.7520e-03,  1.7119e-02,  9.8081e-03],\n",
      "          [ 1.4798e-02,  4.1194e-03, -1.3771e-02]],\n",
      "\n",
      "         [[-1.5233e-02,  1.3551e-02, -2.0632e-02],\n",
      "          [-2.3611e-02, -8.3528e-03, -9.5733e-03],\n",
      "          [ 4.2220e-03, -2.0068e-02, -1.0721e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.5567e-02,  2.9905e-03, -1.3105e-03],\n",
      "          [ 7.5328e-03,  1.0540e-03, -8.9604e-03],\n",
      "          [ 1.1919e-02, -2.0333e-02,  1.1277e-02]],\n",
      "\n",
      "         [[-1.4797e-02, -2.7933e-02, -1.8613e-02],\n",
      "          [-8.9336e-03, -2.1311e-02,  1.1563e-02],\n",
      "          [-1.8292e-02, -1.0564e-02,  8.8539e-03]],\n",
      "\n",
      "         [[ 7.5510e-03, -1.7696e-02,  2.2954e-02],\n",
      "          [ 1.5068e-02, -1.9498e-02,  6.5416e-03],\n",
      "          [ 7.2794e-03,  6.3342e-03, -1.2562e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4782e-02,  9.2544e-03,  1.0889e-02],\n",
      "          [ 1.2987e-02, -4.6036e-03,  7.1213e-03],\n",
      "          [ 1.3434e-02,  1.7376e-02, -6.9616e-03]],\n",
      "\n",
      "         [[ 1.7251e-02,  9.4933e-03,  7.3866e-03],\n",
      "          [-5.5002e-04,  1.8439e-02, -1.9644e-02],\n",
      "          [ 1.3928e-02, -1.0693e-02,  6.8525e-03]],\n",
      "\n",
      "         [[ 1.1898e-02, -7.7516e-03,  5.9378e-03],\n",
      "          [-1.2047e-02, -1.5642e-02, -3.7413e-03],\n",
      "          [ 8.4166e-03, -1.6083e-02, -8.2126e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0965e-03,  1.1811e-02,  1.0026e-02],\n",
      "          [-1.6228e-02, -8.9074e-03, -1.7463e-02],\n",
      "          [ 5.3592e-04,  5.2564e-03,  8.8152e-03]],\n",
      "\n",
      "         [[-9.7533e-03, -2.3786e-02,  1.4021e-02],\n",
      "          [-1.3812e-02,  3.7859e-03, -1.3036e-02],\n",
      "          [ 1.3744e-02,  5.6420e-03, -1.3095e-02]],\n",
      "\n",
      "         [[-2.9256e-03,  1.3140e-03, -1.8991e-02],\n",
      "          [ 1.4559e-02,  2.0638e-02, -1.8595e-02],\n",
      "          [ 2.4307e-02, -1.6649e-02, -9.7544e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.5886e-03, -9.7889e-03, -2.5328e-02],\n",
      "          [ 7.6893e-03,  1.1164e-02, -1.4638e-03],\n",
      "          [ 1.0590e-02, -1.2034e-02, -1.9450e-02]],\n",
      "\n",
      "         [[-6.9263e-03,  6.7661e-03, -1.2155e-03],\n",
      "          [ 5.8199e-03, -1.4262e-02,  1.7956e-03],\n",
      "          [ 1.8611e-02, -1.0038e-02,  1.3823e-02]],\n",
      "\n",
      "         [[-1.8953e-03, -1.8043e-03, -1.4376e-02],\n",
      "          [-1.5568e-02,  3.6664e-03, -8.3997e-03],\n",
      "          [-9.8523e-03, -2.0578e-02, -1.8944e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.7339e-02, -1.3159e-02, -2.4777e-02],\n",
      "          [ 1.2996e-02, -3.8284e-03,  1.0948e-02],\n",
      "          [-1.1818e-04, -5.9038e-03, -9.2570e-03]],\n",
      "\n",
      "         [[-6.0954e-03,  1.4979e-02,  2.2642e-03],\n",
      "          [-1.5772e-02, -1.2485e-02, -1.5311e-02],\n",
      "          [-1.9398e-02, -9.4981e-03, -2.7639e-03]],\n",
      "\n",
      "         [[-1.9357e-02, -1.9555e-02,  8.2618e-03],\n",
      "          [-4.5806e-03, -2.0847e-02, -1.6082e-02],\n",
      "          [ 7.5612e-03,  1.5722e-02,  2.7652e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.9314e-04,  1.0135e-02,  9.5178e-03],\n",
      "          [ 1.5359e-02, -6.5681e-03,  9.2817e-03],\n",
      "          [ 1.4442e-02,  1.3931e-02,  1.5862e-02]],\n",
      "\n",
      "         [[-1.0099e-03, -3.2840e-03, -9.1707e-03],\n",
      "          [-1.7978e-02,  3.1226e-03, -1.6462e-02],\n",
      "          [-1.4206e-02, -3.4260e-03,  1.3717e-03]],\n",
      "\n",
      "         [[ 8.8407e-03, -1.9302e-02,  1.1118e-03],\n",
      "          [ 1.3251e-02, -1.7307e-02,  1.1116e-02],\n",
      "          [-1.6023e-02, -1.6049e-02, -5.2237e-03]]]], device='cuda:0'), 'conv_block_1.2.bias': tensor([-2.2608e-02,  1.4026e-02, -5.2453e-02, -5.7658e-03, -6.4695e-03,\n",
      "         4.5413e-03,  1.3991e-02, -1.3691e-03,  2.7663e-03, -2.0249e-02,\n",
      "        -2.0595e-02,  6.4925e-03, -1.5729e-02,  4.7309e-03,  6.9170e-03,\n",
      "         6.8071e-02, -1.1815e-02,  1.9846e-03, -1.4249e-02, -2.2934e-02,\n",
      "         4.7900e-03,  1.0604e-02, -2.0768e-02, -5.3553e-03, -5.7600e-04,\n",
      "        -6.3440e-03, -2.4509e-02, -9.0215e-03, -2.2801e-02,  1.0145e-02,\n",
      "         1.4033e-02, -2.4693e-02,  1.3863e-02, -1.6401e-02, -7.0256e-03,\n",
      "        -1.1726e-02, -2.4621e-02, -2.0094e-03,  8.8690e-02, -2.3482e-02,\n",
      "        -3.1871e-03, -1.2179e-02, -2.6030e-02,  1.0616e-01,  1.5546e-02,\n",
      "         1.9753e-03, -3.8015e-02,  1.7316e-04,  8.1995e-02, -1.3779e-02,\n",
      "         1.2297e-02,  1.3485e-02, -2.3395e-02, -3.0655e-03, -2.8346e-02,\n",
      "         1.1265e-02, -2.5079e-02, -2.0167e-02, -4.0414e-02, -2.8477e-02,\n",
      "         1.3575e-02,  1.4487e-02, -1.0291e-02, -1.4103e-02, -1.5271e-03,\n",
      "        -1.5599e-02, -2.0037e-02, -9.9559e-03, -1.4749e-02,  7.6396e-03,\n",
      "         4.6759e-03,  2.4135e-03, -9.2204e-03,  1.6052e-02, -1.4709e-02,\n",
      "         1.4692e-03, -6.8689e-03, -1.3354e-02, -2.6780e-02, -1.9842e-02,\n",
      "        -1.0521e-02,  6.0197e-02,  4.2076e-03, -2.7201e-04,  5.1670e-02,\n",
      "         9.2323e-02, -1.1250e-02,  9.0916e-04, -1.3334e-02,  5.7881e-03,\n",
      "        -3.4293e-02, -1.9298e-02, -2.0860e-02,  1.0621e-02, -2.0656e-02,\n",
      "        -1.3041e-02, -2.0087e-02,  6.6152e-03, -1.2996e-02, -1.7193e-02,\n",
      "        -1.8434e-02,  9.2464e-03, -6.0313e-02, -4.2196e-03, -1.4802e-02,\n",
      "        -1.4923e-02, -5.7333e-05, -1.4211e-02, -2.3496e-02, -3.0137e-03,\n",
      "         2.1521e-03,  8.4362e-03, -2.1713e-02,  3.7212e-02, -2.3047e-02,\n",
      "         7.3508e-03,  1.0364e-02, -2.3088e-02, -1.7361e-02, -1.9157e-02,\n",
      "         5.8031e-03,  4.6871e-04,  8.0340e-03,  2.9468e-03, -1.1677e-02,\n",
      "        -2.4442e-02, -2.3943e-03, -1.7353e-02, -2.0808e-02,  1.2377e-02,\n",
      "        -1.0367e-02,  3.6467e-03, -1.6635e-02, -1.2423e-02, -2.1562e-03,\n",
      "         3.8731e-02,  1.0487e-02, -3.7045e-02, -3.1407e-03, -1.1579e-02,\n",
      "        -2.2586e-02, -2.2545e-02,  4.5778e-03, -2.9668e-02, -1.5719e-02,\n",
      "        -5.7218e-03, -1.9306e-02, -1.0969e-02, -2.5338e-02, -5.0353e-03,\n",
      "        -4.3881e-03, -2.4371e-02,  4.8784e-03,  8.3019e-04, -7.2491e-02,\n",
      "        -2.2482e-02, -1.9581e-02, -1.8035e-02,  1.1797e-02, -2.2840e-02,\n",
      "         1.0740e-02,  1.9224e-04, -4.9719e-02,  9.1530e-03, -7.7711e-03,\n",
      "         5.3154e-03,  7.8067e-03, -2.0926e-02,  3.0167e-03, -2.6102e-02,\n",
      "        -1.3223e-02, -5.6183e-03, -1.3888e-02, -6.8123e-03, -1.6642e-02,\n",
      "        -7.5381e-03,  2.5503e-03, -2.3015e-02,  1.0333e-02, -2.5745e-02,\n",
      "        -2.0050e-02, -2.4770e-02, -2.3168e-02, -8.0529e-03, -1.2865e-02,\n",
      "         7.1783e-02, -4.0994e-03,  7.8827e-02,  4.0969e-02, -1.9748e-02,\n",
      "        -1.9961e-02, -4.5895e-03, -5.0001e-02, -1.6948e-02,  1.7210e-02,\n",
      "        -2.2422e-02, -1.0179e-02, -1.5110e-02,  1.3305e-02,  2.1456e-03,\n",
      "        -8.6388e-03, -1.4070e-02,  3.5593e-05, -1.6440e-02, -1.7811e-02,\n",
      "        -7.3151e-03,  1.0248e-02, -8.6852e-03, -2.2719e-02, -1.9009e-02,\n",
      "        -1.0570e-02,  7.1391e-03, -1.0901e-02,  2.2310e-03,  3.1709e-03,\n",
      "        -2.4194e-02, -1.2759e-03, -2.6656e-02, -1.6200e-02, -9.7251e-03,\n",
      "        -2.1955e-03, -4.6631e-03, -2.0524e-02,  7.0077e-03, -1.3798e-02,\n",
      "        -9.5119e-03, -5.7027e-02, -1.4988e-02, -3.8725e-03, -2.0383e-02,\n",
      "         1.2644e-02,  1.1474e-02, -7.0970e-03, -9.7090e-03,  5.4272e-03,\n",
      "         5.6400e-03,  1.3993e-02, -2.7974e-03, -2.4792e-02, -2.2741e-02,\n",
      "         5.6756e-03, -1.8759e-02, -8.1118e-03, -1.6308e-02, -2.3866e-02,\n",
      "        -2.0197e-02, -1.6252e-02, -9.8709e-03,  1.1032e-02, -6.1178e-03,\n",
      "         1.0230e-02, -1.3318e-02, -2.3672e-02, -9.0167e-03, -1.5971e-02,\n",
      "        -8.0774e-03,  1.4045e-01, -7.9365e-03, -2.4272e-03,  7.4741e-03],\n",
      "       device='cuda:0'), 'conv_block_2.0.weight': tensor([[[[ 3.7942e-04,  1.3157e-02, -2.2817e-02],\n",
      "          [-2.6320e-02,  1.0524e-02,  1.3855e-02],\n",
      "          [-2.4230e-03, -4.6394e-03, -2.4538e-02]],\n",
      "\n",
      "         [[ 3.3522e-03,  1.4844e-03, -2.2635e-02],\n",
      "          [-1.8463e-02, -1.6900e-03, -1.5220e-02],\n",
      "          [-2.4184e-02,  1.5156e-02, -2.4762e-02]],\n",
      "\n",
      "         [[-7.1839e-03,  6.8496e-03,  2.3106e-02],\n",
      "          [ 7.3589e-03,  6.9588e-04, -8.1997e-03],\n",
      "          [-8.6868e-03,  1.7401e-02,  1.8731e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3951e-03, -2.3026e-03,  8.5401e-03],\n",
      "          [-4.8248e-03,  7.9174e-03,  2.6099e-03],\n",
      "          [ 4.1731e-04, -1.2696e-02,  9.6260e-03]],\n",
      "\n",
      "         [[-2.5891e-03,  1.0489e-02,  1.5267e-02],\n",
      "          [-2.3750e-02,  4.7026e-03, -4.0698e-03],\n",
      "          [-2.1698e-02, -1.2095e-02,  6.0754e-03]],\n",
      "\n",
      "         [[ 1.3529e-02,  4.9480e-03,  3.0298e-03],\n",
      "          [ 6.0008e-03, -1.0025e-02, -1.0796e-02],\n",
      "          [-1.8555e-02, -2.2922e-02, -1.4926e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4260e-02,  3.8655e-03,  2.6962e-03],\n",
      "          [-1.4229e-02, -1.5792e-02, -2.5642e-02],\n",
      "          [ 1.3679e-02,  5.8518e-03,  5.3462e-03]],\n",
      "\n",
      "         [[-8.1735e-04, -1.2537e-02, -2.0834e-02],\n",
      "          [-1.6992e-02,  1.2517e-02,  3.9855e-03],\n",
      "          [-1.4274e-02, -1.2224e-02, -9.1399e-03]],\n",
      "\n",
      "         [[-7.9024e-04,  1.7219e-02, -5.9183e-03],\n",
      "          [-2.6825e-02, -2.9946e-02, -4.5416e-02],\n",
      "          [-5.6388e-02, -3.3302e-02, -2.4005e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.7802e-03,  1.8843e-03, -2.1675e-02],\n",
      "          [-2.5290e-02, -2.1617e-02, -1.6481e-02],\n",
      "          [ 7.7031e-04,  2.6286e-02, -2.9713e-03]],\n",
      "\n",
      "         [[-2.1454e-02, -1.0739e-02, -2.6782e-03],\n",
      "          [-3.9537e-03, -4.1043e-03, -4.9384e-03],\n",
      "          [-1.2595e-02, -1.8553e-02,  2.2171e-02]],\n",
      "\n",
      "         [[ 1.0017e-03, -1.3895e-02,  5.3469e-03],\n",
      "          [-3.4349e-05, -1.1450e-02, -1.8154e-02],\n",
      "          [ 3.9112e-03, -7.1895e-03,  7.3424e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1411e-02, -4.1304e-03, -8.6619e-03],\n",
      "          [ 6.6951e-03, -2.1686e-02, -1.2441e-02],\n",
      "          [ 4.4526e-03, -8.7518e-03, -1.4096e-02]],\n",
      "\n",
      "         [[-1.5404e-02, -8.1523e-03, -1.5588e-02],\n",
      "          [-1.3982e-02, -1.4813e-02, -1.9022e-02],\n",
      "          [-4.3989e-03, -1.4559e-02,  1.1427e-02]],\n",
      "\n",
      "         [[-7.5464e-03,  2.8775e-02,  2.6226e-02],\n",
      "          [ 3.0577e-02,  4.1944e-02, -5.7049e-03],\n",
      "          [ 4.1918e-02,  8.1815e-03, -8.9943e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.4610e-03, -2.2851e-03,  3.8438e-03],\n",
      "          [ 1.4148e-02,  8.7643e-03,  8.1530e-03],\n",
      "          [ 1.4107e-02, -2.2005e-02, -1.5482e-02]],\n",
      "\n",
      "         [[-9.7138e-03,  1.9025e-03,  9.3067e-03],\n",
      "          [-2.9195e-03, -1.0169e-02, -1.7103e-02],\n",
      "          [ 2.2299e-02,  1.9800e-02,  1.1647e-02]],\n",
      "\n",
      "         [[ 1.3890e-02,  8.1812e-03, -3.0099e-03],\n",
      "          [-1.4732e-02,  5.1831e-03, -3.0799e-03],\n",
      "          [ 3.8253e-03, -5.1950e-04, -2.5179e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.5174e-03,  1.4529e-02, -1.5850e-02],\n",
      "          [-1.5697e-02, -1.7475e-03,  1.4481e-02],\n",
      "          [-1.8584e-03, -9.3000e-03, -1.0170e-02]],\n",
      "\n",
      "         [[-2.5835e-02,  4.1185e-03, -1.5321e-02],\n",
      "          [-7.0345e-03, -1.3019e-02,  4.1507e-03],\n",
      "          [-1.7040e-02,  9.2196e-03, -8.8141e-04]],\n",
      "\n",
      "         [[ 4.5474e-02, -3.2832e-02, -1.4670e-02],\n",
      "          [ 3.0874e-02, -2.3079e-02,  1.3354e-02],\n",
      "          [ 7.2824e-03,  4.3047e-02,  2.8025e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5424e-02, -9.1189e-03,  2.0890e-02],\n",
      "          [ 1.3290e-03, -1.3975e-02,  2.4837e-02],\n",
      "          [-1.3703e-02, -1.2524e-02,  7.2632e-03]],\n",
      "\n",
      "         [[-1.4421e-02, -2.2655e-02,  1.6562e-02],\n",
      "          [-1.9494e-02,  1.2894e-02,  2.7353e-03],\n",
      "          [-2.0646e-02,  2.2282e-03,  1.3501e-02]],\n",
      "\n",
      "         [[-1.9473e-02, -1.0497e-02, -1.2068e-02],\n",
      "          [-8.6807e-03, -1.9019e-02, -4.4654e-03],\n",
      "          [-7.2996e-03,  1.5483e-02, -9.5144e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3101e-02,  1.1980e-02, -1.1027e-02],\n",
      "          [ 5.6696e-03, -2.6340e-02, -6.0344e-03],\n",
      "          [-8.2029e-03, -2.5809e-02,  1.2590e-02]],\n",
      "\n",
      "         [[ 2.6905e-03,  1.4726e-02,  6.4537e-03],\n",
      "          [-6.9603e-03,  4.8973e-03, -4.4827e-03],\n",
      "          [ 1.2190e-02, -1.7819e-02, -2.1717e-02]],\n",
      "\n",
      "         [[ 3.0393e-02,  4.2057e-03,  3.6210e-02],\n",
      "          [ 4.8491e-02, -3.0012e-02,  4.0479e-03],\n",
      "          [ 2.3096e-02, -1.0586e-03,  2.3169e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1578e-02,  8.3036e-03, -3.6076e-03],\n",
      "          [-1.9323e-02,  5.9533e-03, -1.9416e-02],\n",
      "          [ 1.9901e-03, -1.0876e-02, -1.5681e-02]],\n",
      "\n",
      "         [[-2.0486e-02, -7.7889e-03,  5.2263e-03],\n",
      "          [-2.5978e-02,  4.0602e-03, -9.4337e-03],\n",
      "          [-7.2121e-03, -2.6234e-02,  3.7499e-03]],\n",
      "\n",
      "         [[-1.5196e-02, -1.0020e-02, -2.8211e-02],\n",
      "          [ 1.1598e-02, -1.1024e-03, -1.9287e-02],\n",
      "          [-1.3831e-02, -8.7160e-03,  9.5955e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2479e-02,  1.5171e-02,  9.4989e-03],\n",
      "          [-1.9632e-03, -1.7200e-02, -1.9652e-02],\n",
      "          [-2.2356e-02, -2.0952e-02,  7.9418e-03]],\n",
      "\n",
      "         [[ 6.0368e-03, -2.5144e-02,  4.6489e-03],\n",
      "          [-2.3411e-02, -5.0321e-03, -2.0014e-02],\n",
      "          [-2.5464e-02, -1.7374e-03, -1.2612e-03]],\n",
      "\n",
      "         [[-3.4005e-04,  1.6492e-03, -4.9150e-03],\n",
      "          [ 2.4883e-02, -3.9351e-03,  1.9415e-02],\n",
      "          [-1.3261e-02,  1.0101e-02, -1.2425e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0246e-03,  2.1516e-02,  2.3592e-03],\n",
      "          [ 1.9455e-02, -2.3629e-03,  2.5219e-02],\n",
      "          [ 2.3111e-02,  9.5685e-03,  2.3883e-02]],\n",
      "\n",
      "         [[-4.3079e-03,  7.5112e-03,  4.6543e-03],\n",
      "          [-2.6904e-03, -1.8859e-02,  1.3852e-02],\n",
      "          [ 1.4164e-02,  4.1372e-03, -1.3055e-02]],\n",
      "\n",
      "         [[ 3.0786e-03,  5.9480e-03,  3.2519e-03],\n",
      "          [-2.0863e-02,  1.0150e-02,  4.2566e-03],\n",
      "          [-3.2987e-03, -2.1712e-02,  1.2536e-03]]]], device='cuda:0'), 'conv_block_2.0.bias': tensor([-0.0028, -0.1169,  0.0868, -0.0252, -0.0548,  0.0055, -0.0328,  0.1005,\n",
      "         0.0167,  0.0010,  0.0112,  0.0076, -0.0207, -0.0292, -0.0291, -0.0805,\n",
      "        -0.0357, -0.0050,  0.0064,  0.0473, -0.0470, -0.0417, -0.0276,  0.0070,\n",
      "        -0.0039,  0.0025, -0.0155, -0.0570, -0.0392, -0.0616, -0.0168, -0.0719,\n",
      "        -0.0320, -0.0565, -0.0239, -0.0115, -0.0155, -0.0315, -0.0103, -0.0338,\n",
      "        -0.0486, -0.0506, -0.0187, -0.0391, -0.0185, -0.0404, -0.0487,  0.0171,\n",
      "        -0.0250, -0.0104, -0.0204, -0.0150, -0.0431,  0.0074,  0.0172,  0.0012,\n",
      "        -0.0356, -0.0446, -0.0174,  0.0732,  0.0285, -0.0212, -0.0605, -0.0754,\n",
      "        -0.0195,  0.0015, -0.0292, -0.0139,  0.0091, -0.0990, -0.0081, -0.0102,\n",
      "         0.0517, -0.0194, -0.0057, -0.0196, -0.0276, -0.0527, -0.0708, -0.0003,\n",
      "         0.0464, -0.0031, -0.1097, -0.0419, -0.0041, -0.0115, -0.0091, -0.0956,\n",
      "        -0.0168, -0.0560, -0.0824, -0.0284,  0.0299, -0.0003, -0.0672,  0.1254,\n",
      "        -0.0102, -0.0111, -0.0400, -0.0112, -0.0166,  0.0804, -0.0170, -0.0081,\n",
      "        -0.0597, -0.0039, -0.0085,  0.0337, -0.0101, -0.0083, -0.0663, -0.0033,\n",
      "        -0.0400, -0.0263, -0.0064, -0.0446, -0.0196, -0.0602, -0.0451, -0.0045,\n",
      "        -0.0025, -0.0734, -0.1016, -0.0367, -0.0256, -0.0369, -0.0046, -0.0040,\n",
      "        -0.0271, -0.0109, -0.0533,  0.0121, -0.0226,  0.1662, -0.0657, -0.0675,\n",
      "         0.0103, -0.0003, -0.0149, -0.0788, -0.0245, -0.0062, -0.0416,  0.0697,\n",
      "        -0.0525,  0.0016, -0.0275, -0.0092, -0.0164, -0.0433, -0.0523, -0.0967,\n",
      "        -0.1187, -0.0335, -0.0168, -0.0400, -0.0175, -0.0275, -0.0289,  0.0079,\n",
      "        -0.0025, -0.0287, -0.0378, -0.0796, -0.0163, -0.0620, -0.0212, -0.0323,\n",
      "        -0.0097, -0.0227,  0.0364, -0.0045, -0.0458, -0.0194, -0.0468, -0.0204,\n",
      "         0.0291,  0.0860,  0.0189, -0.0801,  0.0554, -0.0136, -0.0360,  0.0026,\n",
      "         0.0778, -0.0433, -0.0397,  0.0020,  0.0247,  0.0609, -0.0114,  0.0127,\n",
      "        -0.0298,  0.0240, -0.0234, -0.0182, -0.0327, -0.0122, -0.0188, -0.0146,\n",
      "        -0.0698, -0.0215, -0.0253, -0.0555, -0.0426, -0.0984, -0.0056, -0.0415,\n",
      "        -0.0479, -0.0307,  0.0210, -0.0241, -0.0390, -0.0234, -0.0289, -0.0476,\n",
      "        -0.0220, -0.0226, -0.0024, -0.0424, -0.0363, -0.0277, -0.0166, -0.0087,\n",
      "        -0.0468,  0.0395, -0.0412, -0.0276, -0.0125, -0.0139, -0.0119, -0.0014,\n",
      "         0.0290, -0.0199, -0.0344, -0.0726, -0.0269, -0.0197, -0.0009, -0.0811,\n",
      "         0.0071, -0.0274, -0.0380, -0.0206,  0.0389, -0.0079, -0.0584, -0.0391,\n",
      "        -0.0047, -0.0235,  0.0101, -0.0459,  0.0066,  0.0003, -0.0227, -0.1411,\n",
      "        -0.0540,  0.0159,  0.1108, -0.0129], device='cuda:0'), 'conv_block_2.2.weight': tensor([[[[-0.0074, -0.0186,  0.0126],\n",
      "          [-0.0166, -0.0075, -0.0267],\n",
      "          [-0.0128, -0.0190, -0.0130]],\n",
      "\n",
      "         [[ 0.0120,  0.0217, -0.0130],\n",
      "          [-0.0020,  0.0209,  0.0042],\n",
      "          [ 0.0168, -0.0018,  0.0090]],\n",
      "\n",
      "         [[-0.0048, -0.0025, -0.0064],\n",
      "          [-0.0304,  0.0101,  0.0015],\n",
      "          [-0.0268, -0.0294, -0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0041, -0.0226,  0.0043],\n",
      "          [-0.0218,  0.0042,  0.0084],\n",
      "          [-0.0029, -0.0009, -0.0197]],\n",
      "\n",
      "         [[-0.0209, -0.0155, -0.0240],\n",
      "          [-0.0129, -0.0060, -0.0307],\n",
      "          [-0.0204,  0.0050, -0.0367]],\n",
      "\n",
      "         [[ 0.0139, -0.0114,  0.0091],\n",
      "          [ 0.0023, -0.0112, -0.0254],\n",
      "          [-0.0074, -0.0093, -0.0099]]],\n",
      "\n",
      "\n",
      "        [[[-0.0117,  0.0211, -0.0239],\n",
      "          [-0.0128,  0.0202, -0.0168],\n",
      "          [ 0.0130, -0.0068, -0.0090]],\n",
      "\n",
      "         [[-0.0345,  0.0119,  0.0108],\n",
      "          [ 0.0002,  0.0542,  0.0298],\n",
      "          [-0.0093,  0.0189, -0.0186]],\n",
      "\n",
      "         [[-0.0142, -0.0528, -0.0215],\n",
      "          [-0.0264, -0.0546, -0.0448],\n",
      "          [-0.0219, -0.0034, -0.0166]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0145,  0.0517,  0.0079],\n",
      "          [ 0.0017,  0.0492,  0.0247],\n",
      "          [-0.0127,  0.0066,  0.0117]],\n",
      "\n",
      "         [[-0.0037,  0.0015, -0.0154],\n",
      "          [-0.0176,  0.0162, -0.0089],\n",
      "          [ 0.0028, -0.0151, -0.0097]],\n",
      "\n",
      "         [[ 0.0017,  0.0098,  0.0026],\n",
      "          [-0.0127, -0.0241, -0.0220],\n",
      "          [ 0.0035, -0.0266, -0.0160]]],\n",
      "\n",
      "\n",
      "        [[[-0.0228,  0.0130,  0.0121],\n",
      "          [ 0.0104, -0.0256, -0.0179],\n",
      "          [-0.0137, -0.0050,  0.0077]],\n",
      "\n",
      "         [[-0.0387, -0.0004, -0.0231],\n",
      "          [-0.0285,  0.0137, -0.0399],\n",
      "          [-0.0066, -0.0232, -0.0320]],\n",
      "\n",
      "         [[ 0.0040, -0.0006, -0.0288],\n",
      "          [ 0.0254, -0.0053, -0.0325],\n",
      "          [-0.0476, -0.0321, -0.0445]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0260, -0.0134, -0.0266],\n",
      "          [-0.0462, -0.0407, -0.0183],\n",
      "          [-0.0186, -0.0152, -0.0180]],\n",
      "\n",
      "         [[-0.0692,  0.0005, -0.0147],\n",
      "          [-0.0350, -0.0429, -0.0616],\n",
      "          [-0.0568, -0.0226, -0.0874]],\n",
      "\n",
      "         [[ 0.0028, -0.0096, -0.0184],\n",
      "          [-0.0167,  0.0017, -0.0058],\n",
      "          [-0.0085,  0.0045, -0.0044]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0161, -0.0240, -0.0069],\n",
      "          [-0.0137, -0.0177, -0.0030],\n",
      "          [ 0.0041, -0.0074,  0.0062]],\n",
      "\n",
      "         [[-0.0381, -0.0197, -0.0366],\n",
      "          [-0.0146, -0.0741, -0.0209],\n",
      "          [-0.0236, -0.0121, -0.0009]],\n",
      "\n",
      "         [[-0.0267, -0.0105, -0.0087],\n",
      "          [-0.0844, -0.0271,  0.0026],\n",
      "          [-0.0537, -0.0084,  0.0050]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0044, -0.0489, -0.0104],\n",
      "          [-0.0030, -0.0695, -0.0131],\n",
      "          [-0.0231, -0.0538, -0.0570]],\n",
      "\n",
      "         [[-0.0077, -0.0142,  0.0100],\n",
      "          [-0.0099, -0.0145, -0.0189],\n",
      "          [-0.0450, -0.0462, -0.0203]],\n",
      "\n",
      "         [[-0.0066,  0.0080, -0.0113],\n",
      "          [-0.0230, -0.0210, -0.0149],\n",
      "          [ 0.0089, -0.0143,  0.0117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0095,  0.0072, -0.0156],\n",
      "          [-0.0168, -0.0201, -0.0025],\n",
      "          [ 0.0147, -0.0223, -0.0148]],\n",
      "\n",
      "         [[-0.0028,  0.0162,  0.0185],\n",
      "          [ 0.0134,  0.0091, -0.0130],\n",
      "          [ 0.0082, -0.0258, -0.0345]],\n",
      "\n",
      "         [[ 0.0564,  0.0479, -0.0041],\n",
      "          [ 0.0459,  0.0355,  0.0027],\n",
      "          [-0.0421, -0.0633, -0.0303]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0045, -0.0291, -0.0562],\n",
      "          [-0.0311, -0.0164, -0.0622],\n",
      "          [-0.0109, -0.0133, -0.0704]],\n",
      "\n",
      "         [[ 0.0152, -0.0367, -0.0143],\n",
      "          [-0.0113, -0.0594, -0.0487],\n",
      "          [-0.0740, -0.0151, -0.0997]],\n",
      "\n",
      "         [[-0.0063,  0.0062, -0.0198],\n",
      "          [-0.0136, -0.0095,  0.0090],\n",
      "          [ 0.0144, -0.0143,  0.0074]]],\n",
      "\n",
      "\n",
      "        [[[-0.0049,  0.0130, -0.0128],\n",
      "          [-0.0147,  0.0014,  0.0072],\n",
      "          [-0.0252, -0.0032, -0.0054]],\n",
      "\n",
      "         [[-0.0108,  0.0251,  0.0082],\n",
      "          [ 0.0199,  0.0250, -0.0027],\n",
      "          [-0.0135,  0.0069,  0.0176]],\n",
      "\n",
      "         [[-0.0384, -0.0109,  0.0098],\n",
      "          [-0.0099, -0.0174, -0.0040],\n",
      "          [ 0.0162,  0.0232, -0.0130]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0072, -0.0251, -0.0123],\n",
      "          [-0.0080,  0.0120, -0.0200],\n",
      "          [-0.0253,  0.0041, -0.0063]],\n",
      "\n",
      "         [[-0.0072, -0.0202,  0.0073],\n",
      "          [-0.0137, -0.0112, -0.0388],\n",
      "          [ 0.0176, -0.0113, -0.0169]],\n",
      "\n",
      "         [[-0.0029,  0.0110, -0.0054],\n",
      "          [-0.0052, -0.0189, -0.0134],\n",
      "          [-0.0041,  0.0089, -0.0025]]]], device='cuda:0'), 'conv_block_2.2.bias': tensor([ 5.6142e-03, -5.6420e-02, -3.1228e-02, -1.1957e-02,  6.2144e-03,\n",
      "        -9.2890e-04, -2.7283e-02, -8.5531e-03,  2.3209e-03, -6.7387e-03,\n",
      "        -8.9480e-03, -2.5486e-02,  8.6215e-02,  9.2946e-03,  8.8771e-03,\n",
      "         1.1267e-02, -4.0348e-03,  1.2250e-02, -8.7110e-03,  4.3340e-02,\n",
      "         5.0707e-02,  3.8192e-04,  6.8767e-02, -1.3672e-02, -1.5459e-02,\n",
      "         5.2698e-02, -4.1091e-02, -1.1140e-02, -2.7167e-02, -9.3254e-03,\n",
      "         1.0374e-02,  2.6150e-03,  4.3143e-03, -1.2781e-02, -6.6642e-03,\n",
      "        -5.0458e-02, -2.6722e-02, -1.9832e-03, -1.1769e-02,  6.6831e-03,\n",
      "        -8.3443e-03, -1.5757e-02, -1.3258e-02, -1.5253e-02,  1.5316e-02,\n",
      "         7.3264e-03, -3.4275e-02, -3.1741e-03, -4.3139e-02,  1.7360e-03,\n",
      "        -2.2335e-02, -3.9669e-02,  9.9794e-03, -5.3315e-03, -1.3578e-02,\n",
      "        -3.8601e-03, -5.6952e-02, -1.7771e-02, -3.5672e-03, -2.0802e-02,\n",
      "        -2.9739e-05,  8.5711e-03, -1.2490e-02, -1.9073e-02, -3.8833e-02,\n",
      "        -1.1519e-02,  3.3986e-02, -2.4341e-02, -2.1300e-02, -1.7934e-02,\n",
      "        -1.6681e-02,  1.3009e-01, -2.3324e-02, -4.2563e-03, -1.6243e-02,\n",
      "         8.3316e-03, -4.3515e-02, -1.0059e-02, -8.9954e-04, -3.9722e-02,\n",
      "        -1.3185e-02, -1.4105e-02, -7.0530e-04,  1.8491e-01,  6.6796e-02,\n",
      "        -7.4246e-03, -6.8774e-03, -3.7236e-02, -2.4153e-02, -1.0902e-03,\n",
      "        -3.2645e-02, -1.3146e-03, -1.5025e-02,  5.5839e-03, -1.9249e-02,\n",
      "        -6.0355e-03, -3.2492e-02, -2.4077e-02, -2.4318e-02, -2.2185e-02,\n",
      "         1.0603e-01, -2.6423e-02, -2.9497e-02, -2.4007e-02, -1.0802e-02,\n",
      "        -3.9194e-02,  9.3858e-02,  9.2319e-02,  3.8782e-03, -1.8141e-02,\n",
      "        -4.9324e-02, -5.2741e-02, -8.8322e-03, -1.3607e-02,  1.1352e-03,\n",
      "        -1.3113e-03, -1.7416e-02, -3.8655e-02, -1.1789e-02,  1.1707e-01,\n",
      "         5.6599e-03, -1.3891e-02, -8.0204e-03,  5.5487e-02,  3.4878e-03,\n",
      "        -2.3698e-02,  1.8544e-03, -2.8204e-03,  2.8392e-03, -1.4783e-02,\n",
      "        -6.9418e-03, -1.7866e-02, -2.1567e-02,  8.0520e-03, -1.9324e-03,\n",
      "        -4.0101e-03,  1.5775e-02,  1.8009e-03, -2.3262e-02,  1.1988e-02,\n",
      "        -1.9818e-02, -1.2758e-02, -2.1061e-03, -1.3144e-02, -1.3918e-02,\n",
      "        -2.6330e-02, -9.4020e-03,  8.0095e-03, -1.1840e-02, -4.1325e-03,\n",
      "         1.0780e-02, -4.9256e-03, -6.2995e-02, -1.0327e-02, -8.0464e-03,\n",
      "        -3.9407e-02, -1.6830e-02, -2.0988e-02, -5.2569e-02,  4.6490e-03,\n",
      "        -3.1618e-02, -2.3389e-02, -3.0859e-02,  4.4833e-03,  1.7776e-03,\n",
      "         3.6571e-02, -2.1061e-02,  1.6394e-01, -1.4247e-03,  5.2579e-03,\n",
      "        -1.3475e-02, -1.2943e-02, -4.8030e-03, -6.9707e-03,  1.3509e-02,\n",
      "        -1.7617e-02, -2.3898e-02, -1.3059e-02, -1.4282e-02, -9.6951e-03,\n",
      "        -3.1275e-02, -1.9322e-02, -1.2434e-02, -8.8765e-03, -2.6401e-02,\n",
      "         2.1214e-04, -1.4376e-03, -1.9050e-02, -1.7169e-02, -5.8097e-02,\n",
      "        -6.3452e-02,  3.6974e-03,  6.8779e-04, -2.3369e-02, -3.5892e-03,\n",
      "        -1.3888e-02, -2.0389e-02, -6.6451e-02, -1.3085e-02, -8.7355e-03,\n",
      "         1.2348e-02, -7.5319e-02, -5.0336e-03, -2.6085e-02,  4.6474e-02,\n",
      "        -1.0269e-02, -9.9585e-03,  1.1560e-01, -9.9584e-03, -1.8269e-02,\n",
      "         9.8887e-03, -5.0183e-02,  1.7553e-03, -4.2556e-02, -3.8615e-02,\n",
      "        -5.2283e-02, -7.8186e-05, -6.9433e-03, -3.8144e-02,  8.6771e-04,\n",
      "        -1.3919e-02, -5.3221e-03, -1.2862e-02,  8.3274e-03, -2.1364e-02,\n",
      "         1.0663e-02, -2.1729e-03, -3.0002e-02, -4.1920e-02, -7.2349e-02,\n",
      "        -1.8053e-02, -3.5658e-02, -1.4281e-02, -2.5313e-02, -4.6840e-02,\n",
      "        -1.2853e-02, -9.5514e-03, -2.0763e-02,  5.5503e-02,  1.0224e-01,\n",
      "        -6.7898e-03, -1.2258e-02,  1.1918e-02,  5.8609e-03, -7.8989e-03,\n",
      "        -2.3059e-02,  1.0718e-03, -7.7639e-03, -2.3764e-02, -7.2787e-03,\n",
      "        -5.5906e-04,  5.3766e-03, -1.5826e-02, -1.8439e-02, -2.4822e-02,\n",
      "        -1.0903e-02, -1.7515e-02, -6.5238e-02, -2.2663e-02, -5.8151e-03],\n",
      "       device='cuda:0'), 'classifier.1.weight': tensor([[-0.0079, -0.0083, -0.0033,  ...,  0.0067,  0.0065, -0.0055],\n",
      "        [-0.0001, -0.0028, -0.0043,  ..., -0.0033, -0.0060, -0.0001],\n",
      "        [ 0.0002,  0.0007,  0.0082,  ..., -0.0063, -0.0036,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0006,  0.0033,  0.0012,  ..., -0.0067, -0.0056,  0.0040],\n",
      "        [-0.0028, -0.0063, -0.0009,  ..., -0.0066, -0.0091, -0.0068],\n",
      "        [-0.0037,  0.0011, -0.0069,  ..., -0.0031, -0.0068, -0.0106]],\n",
      "       device='cuda:0'), 'classifier.1.bias': tensor([ 0.1359, -0.0746, -0.0285, -0.0325, -0.0757,  0.0537,  0.0590, -0.0855,\n",
      "         0.0438,  0.0682, -0.0335,  0.0672, -0.0870, -0.0657,  0.0068,  0.0652,\n",
      "        -0.0325,  0.1804, -0.0698, -0.0324,  0.0385, -0.0191, -0.0560, -0.0357,\n",
      "        -0.0567, -0.0308, -0.0152,  0.0500, -0.1151,  0.0398,  0.0498,  0.0168,\n",
      "        -0.0204, -0.0419, -0.0230], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "loaded_model_1 = TinyVGG(\n",
    "    input_shape=3, # Number of color channels in out image data\n",
    "    hidden_units=260,\n",
    "    output_shape=len(train_data.classes),\n",
    "    ).to(device)\n",
    "\n",
    "# Load in the save state_dict()\n",
    "loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "# Send the model to target device\n",
    "print(loaded_model_1.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_and_plot_image(\n",
    "    model=loaded_model_1,\n",
    "    image_path=Path(r\"C:\\Users\\197as\\OneDrive\\Documents\\PBL\\Indian\\k.jpeg\"),\n",
    "    class_names=test_data.classes,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
